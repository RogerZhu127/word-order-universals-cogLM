{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from scipy.stats.distributions import chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_order = [\n",
    "    \"Transformer\",\n",
    "    \"LSTM\",\n",
    "    \"RNN\",\n",
    "    \"5gram\",\n",
    "    \"4gram\",\n",
    "    \"3gram\",\n",
    "    \"Transformer-action_td\",\n",
    "    \"Transformer-action_lc-as\",\n",
    "    \"LSTM-action_td\",\n",
    "    \"LSTM-action_lc-as\",\n",
    "    \"RNN-action_td\",\n",
    "    \"RNN-action_lc-as\",\n",
    "    \"5gram_actions_td\",\n",
    "    \"5gram_actions_lc-as\",\n",
    "    \"4gram_actions_td\",\n",
    "    \"4gram_actions_lc-as\",\n",
    "    \"3gram_actions_td\",\n",
    "    \"3gram_actions_lc-as\",\n",
    "    \"RNNG_top_down\",\n",
    "    \"RNNG_in_order\",\n",
    "    \"SRNNG_top_down\",\n",
    "    \"SRNNG_in_order\",\n",
    "    \"td\",\n",
    "    \"lc-as\",\n",
    "    \"llama2-7b\",\n",
    "]\n",
    "\n",
    "model2name = {\n",
    "    \"random\": \"random & &\",\n",
    "    \"Transformer\": \"Transformer & &\",\n",
    "    \"LSTM\": \"LSTM & \\\\textcolor{gray}{\\checkmark} &\",\n",
    "    \"RNN\": \"SRN  & \\checkmark &\",\n",
    "    \"3gram\": \"Word 3-gram & \\checkmark &\",\n",
    "    \"4gram\": \"Word 4-gram & \\checkmark &\",\n",
    "    \"5gram\": \"Word 5-gram & \\checkmark &\",\n",
    "    \"Transformer-action_td\": \"Trans. PLM & & TD\",\n",
    "    \"Transformer-action_lc-as\": \"Trans. PLM & & LC\",\n",
    "    \"LSTM-action_td\": \"LSTM PLM & \\\\textcolor{gray}{\\checkmark} & TD\",\n",
    "    \"LSTM-action_lc-as\": \"LSTM PLM & \\\\textcolor{gray}{\\checkmark} & LC\",\n",
    "    \"RNN-action_td\": \"SRN PLM & \\checkmark & TD\",\n",
    "    \"RNN-action_lc-as\": \"SRN PLM & \\checkmark & LC\",\n",
    "    \"5gram_actions_td\": \"5-gram PLM & \\checkmark & TD\",\n",
    "    \"4gram_actions_td\": \"4-gram PLM & \\checkmark & TD\",\n",
    "    \"3gram_actions_td\": \"3-gram PLM & \\checkmark & TD\",\n",
    "    \"5gram_actions_lc-as\": \"5-gram PLM & \\checkmark & LC\",\n",
    "    \"4gram_actions_lc-as\": \"4-gram PLM & \\checkmark & LC\",\n",
    "    \"3gram_actions_lc-as\": \"3-gram PLM & \\checkmark & LC\",\n",
    "    \"RNNG_top_down\": \"RNNG & & TD\",\n",
    "    \"SRNNG_top_down\": \"SRNNG & \\checkmark & TD\",\n",
    "    \"RNNG_in_order\": \"RNNG & & LC\",\n",
    "    \"SRNNG_in_order\": \"SRNNG & \\checkmark & LC\",\n",
    "    \"llama2-7b\": \"LLaMA2 (7B) & & \",\n",
    "    \"td\": \"Stack depth & & TD\",\n",
    "    \"lc-as\": \"Stack depth & & LC\",\n",
    "}\n",
    "\n",
    "metrics = [\"model\", \"correl\",  \"micro_correl\", \"consistency\", \"left_pref\"]\n",
    "metrics_detailed = [\"model\", \"correl\",  \"micro_correl\", \"consistency\", \"left_pref\"]\n",
    "ks = [\"0.5\", \"1.0\", \"2.0\", \"3.0\", \"log\"]\n",
    "k2label = {\"0.5\": \"PPL$^{0.5}$\", \"1.0\": \"PPL\", \"2.0\": \"PPL$^2$\", \"3.0\": \"PPL$^3$\", \"log\": \"log(PPL)\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer & & & 12.1 $\\pm$ 4.3 & 16.7 $\\pm$ 6.4 & 23.8 $\\pm$ 6.1 & \\texttt{LLLLLL}, \\texttt{LLRLLL}, \\texttt{RLRLLL} \\\\\n",
      "LSTM & \\textcolor{gray}{\\checkmark} & & 10.7 $\\pm$ 14.7 & 26.9 $\\pm$ 7.4 & -1.2 $\\pm$ 11.3 & \\texttt{RLRLLL}, \\texttt{RLLLLL}, \\texttt{RRRRRR} \\\\\n",
      "SRN  & \\checkmark & & 16.3 $\\pm$ 9.4 & 38.3 $\\pm$ 3.0 & -3.6 $\\pm$ 10.4 & \\texttt{RLLLLL}, \\texttt{RLRLLL}, \\texttt{RLRRLL} \\\\\n",
      "Word 5-gram & \\checkmark & & 5.4 $\\pm$ 1.0 & 17.0 $\\pm$ 1.7 & -5.8 $\\pm$ 1.6 & \\texttt{RRLRRR}, \\texttt{RRRRRR}, \\texttt{LRLRRR} \\\\\n",
      "Word 4-gram & \\checkmark & & 6.5 $\\pm$ 1.0 & 16.5 $\\pm$ 1.6 & -6.4 $\\pm$ 1.6 & \\texttt{RRLRRR}, \\texttt{RRRRRR}, \\texttt{LRLRRR} \\\\\n",
      "Word 3-gram & \\checkmark & & 8.8 $\\pm$ 0.7 & 17.5 $\\pm$ 1.0 & -6.1 $\\pm$ 1.0 & \\texttt{RRRRRR}, \\texttt{RRLRRR}, \\texttt{LRLRRR} \\\\\n",
      "Trans. PLM & & TD & 30.4 $\\pm$ 5.7 & 29.5 $\\pm$ 9.1 & 35.9 $\\pm$ 4.7 & \\texttt{LLRRLL}, \\texttt{LLRRRL}, \\texttt{LLRLLL} \\\\\n",
      "Trans. PLM & & LC & 30.3 $\\pm$ 2.1 & 42.3 $\\pm$ 1.1 & 35.2 $\\pm$ 2.3 & \\texttt{LLLLLL}, \\texttt{LLRLLL}, \\texttt{LLRRLL} \\\\\n",
      "LSTM PLM & \\textcolor{gray}{\\checkmark} & TD & 11.9 $\\pm$ 12.2 & 37.0 $\\pm$ 7.3 & -27.1 $\\pm$ 10.5 & \\texttt{LRRRRL}, \\texttt{LRLRRL}, \\texttt{LRRRRR} \\\\\n",
      "LSTM PLM & \\textcolor{gray}{\\checkmark} & LC & 23.6 $\\pm$ 3.6 & 40.4 $\\pm$ 2.5 & 0.5 $\\pm$ 5.5 & \\texttt{RLLRRR}, \\texttt{LLLLLL}, \\texttt{LLLRLL} \\\\\n",
      "SRN PLM & \\checkmark & TD & -5.4 $\\pm$ 8.3 & 8.7 $\\pm$ 7.8 & -53.7 $\\pm$ 7.4 & \\texttt{RLRRRR}, \\texttt{LRLRRR}, \\texttt{RLLRRR} \\\\\n",
      "SRN PLM & \\checkmark & LC & 9.5 $\\pm$ 4.9 & 27.5 $\\pm$ 10.5 & 2.8 $\\pm$ 5.2 & \\texttt{RLRRLL}, \\texttt{RLRRRR}, \\texttt{RLLRLL} \\\\\n",
      "5-gram PLM & \\checkmark & TD & 11.8 $\\pm$ 2.4 & 50.4 $\\pm$ 2.8 & 10.2 $\\pm$ 7.8 & \\texttt{RLLRRL}, \\texttt{RLRRRL}, \\texttt{RLLLLL} \\\\\n",
      "5-gram PLM & \\checkmark & LC & 18.6 $\\pm$ 0.9 & 47.0 $\\pm$ 1.3 & 28.8 $\\pm$ 1.4 & \\texttt{LLLRLL}, \\texttt{RLLRLL}, \\texttt{RLRRLL} \\\\\n",
      "4-gram PLM & \\checkmark & TD & 29.2 $\\pm$ 0.6 & 40.0 $\\pm$ 1.6 & 4.4 $\\pm$ 5.4 & \\texttt{LLRRRL}, \\texttt{RLRRRL}, \\texttt{LLRRRR} \\\\\n",
      "4-gram PLM & \\checkmark & LC & 21.7 $\\pm$ 0.6 & 50.6 $\\pm$ 0.6 & 22.2 $\\pm$ 0.9 & \\texttt{RLLRLL}, \\texttt{RLRRLL}, \\texttt{LLLRLL} \\\\\n",
      "3-gram PLM & \\checkmark & TD & 19.9 $\\pm$ 0.7 & 29.0 $\\pm$ 1.8 & 17.3 $\\pm$ 2.0 & \\texttt{RLLRRL}, \\texttt{LLLRRL}, \\texttt{RLLRRR} \\\\\n",
      "3-gram PLM & \\checkmark & LC & 18.0 $\\pm$ 0.2 & 55.7 $\\pm$ 0.3 & 27.0 $\\pm$ 0.5 & \\texttt{RLLRRR}, \\texttt{RLLRRL}, \\texttt{RLRRRR} \\\\\n",
      "RNNG & & TD & -22.6 $\\pm$ 4.7 & 6.0 $\\pm$ 14.5 & 14.5 $\\pm$ 10.8 & \\texttt{RLLRLL}, \\texttt{RRRRLL}, \\texttt{RRRLLL} \\\\\n",
      "RNNG & & LC & -17.6 $\\pm$ 6.4 & 25.1 $\\pm$ 13.4 & -21.2 $\\pm$ 2.0 & \\texttt{RRRRRL}, \\texttt{RRLLRL}, \\texttt{RRLRRL} \\\\\n",
      "SRNNG & \\checkmark & TD & 2.0 $\\pm$ 9.3 & 10.7 $\\pm$ 7.8 & 10.2 $\\pm$ 7.0 & \\texttt{RLLRRR}, \\texttt{RLRRRR}, \\texttt{RLLRRL} \\\\\n",
      "SRNNG & \\checkmark & LC & 19.1 $\\pm$ 9.5 & 23.7 $\\pm$ 12.9 & -40.6 $\\pm$ 8.5 & \\texttt{LRRRRR}, \\texttt{LRLRRR}, \\texttt{LLLRRR} \\\\\n",
      "Stack depth & & TD & -47.5 $\\pm$ 0.2 & -12.0 $\\pm$ 0.6 & -56.2 $\\pm$ 1.3 & \\texttt{RRLRRR}, \\texttt{RRLLRR}, \\texttt{RRRRRR} \\\\\n",
      "Stack depth & & LC & -13.1 $\\pm$ 0.9 & -4.4 $\\pm$ 0.7 & 57.7 $\\pm$ 1.8 & \\texttt{RLLLLL}, \\texttt{RLLRLL}, \\texttt{RLRLLL} \\\\\n",
      "LLaMA2 (7B) & &  & 6.9 $\\pm$ 31.0 & 15.4 $\\pm$ 2.5 & -4.6 $\\pm$ 31.0 & \\texttt{LRLLLL}, \\texttt{LRRLLL}, \\texttt{LRLRLL} \\\\\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../work/results/regression/results_20230908.csv\")\n",
    "df_stack = pd.read_csv(\"../work/results/regression/results_20231217_stack_depth.csv\")\n",
    "df = pd.concat([df, df_stack], axis=0)\n",
    "\n",
    "for score, std, top3 in zip(df[df[\"k\"]==\"1.0\"][metrics].groupby(\"model\").mean().reindex(model_order).iterrows(), df[df[\"k\"]==\"1.0\"][metrics].groupby(\"model\").std().reindex(model_order).iterrows(), df[(df[\"k\"]==\"1.0\") & (df[\"fold\"]==0)][[\"model\", \"top3_langs\"]].set_index(\"model\").loc[model_order][\"top3_langs\"].apply(lambda x: \", \".join([\"\\\\texttt{\" + l.replace(\"'\", \"\").strip(\"[] \").replace(\"1\", \"R\").replace(\"0\", \"L\").replace(\"X\", \"\") + \"}\" for l in x.split(\",\")]))):\n",
    "    model = score[0]\n",
    "    if model in model2name:\n",
    "        model = model2name[model]\n",
    "    print(f\"{model} & {score[1]['correl']*100:.1f} $\\pm$ {std[1]['correl']*100:.1f} & {score[1]['micro_correl']*100:.1f} $\\pm$ {std[1]['micro_correl']*100:.1f} & {score[1]['left_pref']*100:.1f} $\\pm$ {std[1]['left_pref']*100:.1f} & {top3} \\\\\\\\\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k (linking function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\multicolumn{9}{c}{PPL$^{0.5}$} \\\\\n",
      "Transformer & & & 12.4 $\\pm$ 4.3 & 16.7 $\\pm$ 6.4 & 24.1 $\\pm$ 6.1 & \\texttt{LLLLLL}, \\texttt{LLRLLL}, \\texttt{RLRLLL} \\\\\n",
      "LSTM & \\textcolor{gray}{\\checkmark} & & 11.2 $\\pm$ 14.7 & 27.0 $\\pm$ 7.4 & -0.8 $\\pm$ 11.3 & \\texttt{RLRLLL}, \\texttt{RLLLLL}, \\texttt{RRRRRR} \\\\\n",
      "SRN  & \\checkmark & & 16.5 $\\pm$ 9.4 & 38.4 $\\pm$ 3.0 & -3.5 $\\pm$ 10.4 & \\texttt{RLLLLL}, \\texttt{RLRLLL}, \\texttt{RLRRLL} \\\\\n",
      "Word 5-gram & \\checkmark & & 5.5 $\\pm$ 1.0 & 17.1 $\\pm$ 1.7 & -6.0 $\\pm$ 1.6 & \\texttt{RRLRRR}, \\texttt{RRRRRR}, \\texttt{LRLRRR} \\\\\n",
      "Word 4-gram & \\checkmark & & 6.6 $\\pm$ 1.0 & 16.7 $\\pm$ 1.6 & -6.7 $\\pm$ 1.6 & \\texttt{RRLRRR}, \\texttt{RRRRRR}, \\texttt{LRLRRR} \\\\\n",
      "Word 3-gram & \\checkmark & & 8.9 $\\pm$ 0.7 & 17.7 $\\pm$ 1.0 & -6.3 $\\pm$ 1.0 & \\texttt{RRRRRR}, \\texttt{RRLRRR}, \\texttt{LRLRRR} \\\\\n",
      "Trans. PLM & & TD & 30.5 $\\pm$ 5.7 & 29.4 $\\pm$ 9.1 & 36.2 $\\pm$ 4.7 & \\texttt{LLRRLL}, \\texttt{LLRRRL}, \\texttt{LLRLLL} \\\\\n",
      "Trans. PLM & & LC & 30.2 $\\pm$ 2.1 & 42.3 $\\pm$ 1.1 & 35.7 $\\pm$ 2.3 & \\texttt{LLLLLL}, \\texttt{LLRLLL}, \\texttt{LLRRLL} \\\\\n",
      "LSTM PLM & \\textcolor{gray}{\\checkmark} & TD & 11.9 $\\pm$ 12.2 & 37.0 $\\pm$ 7.3 & -27.2 $\\pm$ 10.5 & \\texttt{LRRRRL}, \\texttt{LRLRRL}, \\texttt{LRRRRR} \\\\\n",
      "LSTM PLM & \\textcolor{gray}{\\checkmark} & LC & 23.6 $\\pm$ 3.6 & 40.4 $\\pm$ 2.5 & 0.6 $\\pm$ 5.5 & \\texttt{RLLRRR}, \\texttt{LLLLLL}, \\texttt{LLLRLL} \\\\\n",
      "SRN PLM & \\checkmark & TD & -5.4 $\\pm$ 8.3 & 8.8 $\\pm$ 7.8 & -53.8 $\\pm$ 7.4 & \\texttt{RLRRRR}, \\texttt{LRLRRR}, \\texttt{RLLRRR} \\\\\n",
      "SRN PLM & \\checkmark & LC & 9.3 $\\pm$ 4.9 & 27.6 $\\pm$ 10.5 & 2.8 $\\pm$ 5.2 & \\texttt{RLRRLL}, \\texttt{RLRRRR}, \\texttt{RLLRLL} \\\\\n",
      "5-gram PLM & \\checkmark & TD & 11.8 $\\pm$ 2.4 & 50.5 $\\pm$ 2.8 & 10.2 $\\pm$ 7.8 & \\texttt{RLLRRL}, \\texttt{RLRRRL}, \\texttt{RLLLLL} \\\\\n",
      "5-gram PLM & \\checkmark & LC & 18.5 $\\pm$ 0.9 & 47.0 $\\pm$ 1.3 & 29.0 $\\pm$ 1.4 & \\texttt{LLLRLL}, \\texttt{RLLRLL}, \\texttt{RLRRLL} \\\\\n",
      "4-gram PLM & \\checkmark & TD & 29.2 $\\pm$ 0.6 & 40.0 $\\pm$ 1.6 & 4.3 $\\pm$ 5.4 & \\texttt{LLRRRL}, \\texttt{RLRRRL}, \\texttt{LLRRRR} \\\\\n",
      "4-gram PLM & \\checkmark & LC & 21.6 $\\pm$ 0.6 & 50.5 $\\pm$ 0.6 & 22.4 $\\pm$ 0.9 & \\texttt{RLLRLL}, \\texttt{RLRRLL}, \\texttt{LLLRLL} \\\\\n",
      "3-gram PLM & \\checkmark & TD & 19.9 $\\pm$ 0.7 & 29.0 $\\pm$ 1.8 & 17.3 $\\pm$ 2.0 & \\texttt{RLLRRL}, \\texttt{LLLRRL}, \\texttt{RLLRRR} \\\\\n",
      "3-gram PLM & \\checkmark & LC & 17.9 $\\pm$ 0.2 & 55.7 $\\pm$ 0.3 & 27.0 $\\pm$ 0.5 & \\texttt{RLLRRR}, \\texttt{RLLRRL}, \\texttt{RLRRRR} \\\\\n",
      "RNNG & & TD & -22.6 $\\pm$ 4.7 & 6.0 $\\pm$ 14.5 & 14.5 $\\pm$ 10.8 & \\texttt{RLLRLL}, \\texttt{RRRRLL}, \\texttt{RRRLLL} \\\\\n",
      "RNNG & & LC & -17.6 $\\pm$ 6.4 & 25.1 $\\pm$ 13.4 & -21.1 $\\pm$ 2.0 & \\texttt{RRRRRL}, \\texttt{RRLLRL}, \\texttt{RRLRRL} \\\\\n",
      "SRNNG & \\checkmark & TD & 1.9 $\\pm$ 9.3 & 10.7 $\\pm$ 7.8 & 10.1 $\\pm$ 7.0 & \\texttt{RLLRRR}, \\texttt{RLRRRR}, \\texttt{RLLRRL} \\\\\n",
      "SRNNG & \\checkmark & LC & 19.2 $\\pm$ 9.5 & 23.8 $\\pm$ 12.9 & -40.6 $\\pm$ 8.5 & \\texttt{LRRRRR}, \\texttt{LRLRRR}, \\texttt{LLLRRR} \\\\\n",
      "Stack depth & & TD & -47.4 $\\pm$ 0.2 & -12.0 $\\pm$ 0.6 & -56.2 $\\pm$ 1.3 & \\texttt{RRLRRR}, \\texttt{RRLLRR}, \\texttt{RRRRRR} \\\\\n",
      "Stack depth & & LC & -12.4 $\\pm$ 0.9 & -4.5 $\\pm$ 0.7 & 57.6 $\\pm$ 1.8 & \\texttt{RLLLLL}, \\texttt{RLLRLL}, \\texttt{RLRLLL} \\\\\n",
      "LLaMA2 (7B) & &  & 6.9 $\\pm$ 31.0 & 15.4 $\\pm$ 2.5 & -4.6 $\\pm$ 31.0 & \\texttt{LRLLLL}, \\texttt{LRRLLL}, \\texttt{LRLRLL} \\\\\n",
      "\\multicolumn{9}{c}{PPL} \\\\\n",
      "Transformer & & & 12.1 $\\pm$ 4.3 & 16.7 $\\pm$ 6.4 & 23.8 $\\pm$ 6.1 & \\texttt{LLLLLL}, \\texttt{LLRLLL}, \\texttt{RLRLLL} \\\\\n",
      "LSTM & \\textcolor{gray}{\\checkmark} & & 10.7 $\\pm$ 14.7 & 26.9 $\\pm$ 7.4 & -1.2 $\\pm$ 11.3 & \\texttt{RLRLLL}, \\texttt{RLLLLL}, \\texttt{RRRRRR} \\\\\n",
      "SRN  & \\checkmark & & 16.3 $\\pm$ 9.4 & 38.3 $\\pm$ 3.0 & -3.6 $\\pm$ 10.4 & \\texttt{RLLLLL}, \\texttt{RLRLLL}, \\texttt{RLRRLL} \\\\\n",
      "Word 5-gram & \\checkmark & & 5.4 $\\pm$ 1.0 & 17.0 $\\pm$ 1.7 & -5.8 $\\pm$ 1.6 & \\texttt{RRLRRR}, \\texttt{RRRRRR}, \\texttt{LRLRRR} \\\\\n",
      "Word 4-gram & \\checkmark & & 6.5 $\\pm$ 1.0 & 16.5 $\\pm$ 1.6 & -6.4 $\\pm$ 1.6 & \\texttt{RRLRRR}, \\texttt{RRRRRR}, \\texttt{LRLRRR} \\\\\n",
      "Word 3-gram & \\checkmark & & 8.8 $\\pm$ 0.7 & 17.5 $\\pm$ 1.0 & -6.1 $\\pm$ 1.0 & \\texttt{RRRRRR}, \\texttt{RRLRRR}, \\texttt{LRLRRR} \\\\\n",
      "Trans. PLM & & TD & 30.4 $\\pm$ 5.7 & 29.5 $\\pm$ 9.1 & 35.9 $\\pm$ 4.7 & \\texttt{LLRRLL}, \\texttt{LLRRRL}, \\texttt{LLRLLL} \\\\\n",
      "Trans. PLM & & LC & 30.3 $\\pm$ 2.1 & 42.3 $\\pm$ 1.1 & 35.2 $\\pm$ 2.3 & \\texttt{LLLLLL}, \\texttt{LLRLLL}, \\texttt{LLRRLL} \\\\\n",
      "LSTM PLM & \\textcolor{gray}{\\checkmark} & TD & 11.9 $\\pm$ 12.2 & 37.0 $\\pm$ 7.3 & -27.1 $\\pm$ 10.5 & \\texttt{LRRRRL}, \\texttt{LRLRRL}, \\texttt{LRRRRR} \\\\\n",
      "LSTM PLM & \\textcolor{gray}{\\checkmark} & LC & 23.6 $\\pm$ 3.6 & 40.4 $\\pm$ 2.5 & 0.5 $\\pm$ 5.5 & \\texttt{RLLRRR}, \\texttt{LLLLLL}, \\texttt{LLLRLL} \\\\\n",
      "SRN PLM & \\checkmark & TD & -5.4 $\\pm$ 8.3 & 8.7 $\\pm$ 7.8 & -53.7 $\\pm$ 7.4 & \\texttt{RLRRRR}, \\texttt{LRLRRR}, \\texttt{RLLRRR} \\\\\n",
      "SRN PLM & \\checkmark & LC & 9.5 $\\pm$ 4.9 & 27.5 $\\pm$ 10.5 & 2.8 $\\pm$ 5.2 & \\texttt{RLRRLL}, \\texttt{RLRRRR}, \\texttt{RLLRLL} \\\\\n",
      "5-gram PLM & \\checkmark & TD & 11.8 $\\pm$ 2.4 & 50.4 $\\pm$ 2.8 & 10.2 $\\pm$ 7.8 & \\texttt{RLLRRL}, \\texttt{RLRRRL}, \\texttt{RLLLLL} \\\\\n",
      "5-gram PLM & \\checkmark & LC & 18.6 $\\pm$ 0.9 & 47.0 $\\pm$ 1.3 & 28.8 $\\pm$ 1.4 & \\texttt{LLLRLL}, \\texttt{RLLRLL}, \\texttt{RLRRLL} \\\\\n",
      "4-gram PLM & \\checkmark & TD & 29.2 $\\pm$ 0.6 & 40.0 $\\pm$ 1.6 & 4.4 $\\pm$ 5.4 & \\texttt{LLRRRL}, \\texttt{RLRRRL}, \\texttt{LLRRRR} \\\\\n",
      "4-gram PLM & \\checkmark & LC & 21.7 $\\pm$ 0.6 & 50.6 $\\pm$ 0.6 & 22.2 $\\pm$ 0.9 & \\texttt{RLLRLL}, \\texttt{RLRRLL}, \\texttt{LLLRLL} \\\\\n",
      "3-gram PLM & \\checkmark & TD & 19.9 $\\pm$ 0.7 & 29.0 $\\pm$ 1.8 & 17.3 $\\pm$ 2.0 & \\texttt{RLLRRL}, \\texttt{LLLRRL}, \\texttt{RLLRRR} \\\\\n",
      "3-gram PLM & \\checkmark & LC & 18.0 $\\pm$ 0.2 & 55.7 $\\pm$ 0.3 & 27.0 $\\pm$ 0.5 & \\texttt{RLLRRR}, \\texttt{RLLRRL}, \\texttt{RLRRRR} \\\\\n",
      "RNNG & & TD & -22.6 $\\pm$ 4.7 & 6.0 $\\pm$ 14.5 & 14.5 $\\pm$ 10.8 & \\texttt{RLLRLL}, \\texttt{RRRRLL}, \\texttt{RRRLLL} \\\\\n",
      "RNNG & & LC & -17.6 $\\pm$ 6.4 & 25.1 $\\pm$ 13.4 & -21.2 $\\pm$ 2.0 & \\texttt{RRRRRL}, \\texttt{RRLLRL}, \\texttt{RRLRRL} \\\\\n",
      "SRNNG & \\checkmark & TD & 2.0 $\\pm$ 9.3 & 10.7 $\\pm$ 7.8 & 10.2 $\\pm$ 7.0 & \\texttt{RLLRRR}, \\texttt{RLRRRR}, \\texttt{RLLRRL} \\\\\n",
      "SRNNG & \\checkmark & LC & 19.1 $\\pm$ 9.5 & 23.7 $\\pm$ 12.9 & -40.6 $\\pm$ 8.5 & \\texttt{LRRRRR}, \\texttt{LRLRRR}, \\texttt{LLLRRR} \\\\\n",
      "Stack depth & & TD & -47.5 $\\pm$ 0.2 & -12.0 $\\pm$ 0.6 & -56.2 $\\pm$ 1.3 & \\texttt{RRLRRR}, \\texttt{RRLLRR}, \\texttt{RRRRRR} \\\\\n",
      "Stack depth & & LC & -13.1 $\\pm$ 0.9 & -4.4 $\\pm$ 0.7 & 57.7 $\\pm$ 1.8 & \\texttt{RLLLLL}, \\texttt{RLLRLL}, \\texttt{RLRLLL} \\\\\n",
      "LLaMA2 (7B) & &  & 6.9 $\\pm$ 31.0 & 15.4 $\\pm$ 2.5 & -4.6 $\\pm$ 31.0 & \\texttt{LRLLLL}, \\texttt{LRRLLL}, \\texttt{LRLRLL} \\\\\n",
      "\\multicolumn{9}{c}{PPL$^2$} \\\\\n",
      "Transformer & & & 11.6 $\\pm$ 4.3 & 16.5 $\\pm$ 6.4 & 23.1 $\\pm$ 6.1 & \\texttt{LLLLLL}, \\texttt{LLRLLL}, \\texttt{RLRLLL} \\\\\n",
      "LSTM & \\textcolor{gray}{\\checkmark} & & 9.8 $\\pm$ 14.7 & 26.6 $\\pm$ 7.4 & -1.8 $\\pm$ 11.3 & \\texttt{RLRLLL}, \\texttt{RLLLLL}, \\texttt{RRRRRR} \\\\\n",
      "SRN  & \\checkmark & & 16.1 $\\pm$ 9.4 & 38.3 $\\pm$ 3.0 & -3.6 $\\pm$ 10.4 & \\texttt{RLLLLL}, \\texttt{RLRLLL}, \\texttt{RLRRLL} \\\\\n",
      "Word 5-gram & \\checkmark & & 5.4 $\\pm$ 1.0 & 16.7 $\\pm$ 1.7 & -5.3 $\\pm$ 1.6 & \\texttt{RRLRRR}, \\texttt{RRRRRR}, \\texttt{LRLRRR} \\\\\n",
      "Word 4-gram & \\checkmark & & 6.4 $\\pm$ 1.0 & 16.1 $\\pm$ 1.6 & -5.8 $\\pm$ 1.6 & \\texttt{RRLRRR}, \\texttt{RRRRRR}, \\texttt{LRLRRR} \\\\\n",
      "Word 3-gram & \\checkmark & & 8.5 $\\pm$ 0.7 & 17.1 $\\pm$ 1.0 & -5.6 $\\pm$ 1.0 & \\texttt{RRRRRR}, \\texttt{RRLRRR}, \\texttt{LRLRRR} \\\\\n",
      "Trans. PLM & & TD & 30.3 $\\pm$ 5.7 & 29.7 $\\pm$ 9.1 & 35.3 $\\pm$ 4.7 & \\texttt{LLRRLL}, \\texttt{LLRRRL}, \\texttt{LLRLLL} \\\\\n",
      "Trans. PLM & & LC & 30.3 $\\pm$ 2.1 & 42.5 $\\pm$ 1.1 & 34.1 $\\pm$ 2.3 & \\texttt{LLLLLL}, \\texttt{LLRLLL}, \\texttt{LLRRLL} \\\\\n",
      "LSTM PLM & \\textcolor{gray}{\\checkmark} & TD & 11.8 $\\pm$ 12.2 & 37.0 $\\pm$ 7.3 & -27.1 $\\pm$ 10.5 & \\texttt{LRRRRL}, \\texttt{LRLRRL}, \\texttt{LRRRRR} \\\\\n",
      "LSTM PLM & \\textcolor{gray}{\\checkmark} & LC & 23.6 $\\pm$ 3.6 & 40.4 $\\pm$ 2.5 & 0.4 $\\pm$ 5.5 & \\texttt{RLLRRR}, \\texttt{LLLLLL}, \\texttt{LLLRLL} \\\\\n",
      "SRN PLM & \\checkmark & TD & -5.5 $\\pm$ 8.3 & 8.7 $\\pm$ 7.8 & -53.7 $\\pm$ 7.4 & \\texttt{RLRRRR}, \\texttt{LRLRRR}, \\texttt{RLLRRR} \\\\\n",
      "SRN PLM & \\checkmark & LC & 9.9 $\\pm$ 4.9 & 27.4 $\\pm$ 10.5 & 2.8 $\\pm$ 5.2 & \\texttt{RLRRLL}, \\texttt{RLRRRR}, \\texttt{RLLRLL} \\\\\n",
      "5-gram PLM & \\checkmark & TD & 11.9 $\\pm$ 2.4 & 50.4 $\\pm$ 2.8 & 10.2 $\\pm$ 7.8 & \\texttt{RLLRRL}, \\texttt{RLRRRL}, \\texttt{RLLLLL} \\\\\n",
      "5-gram PLM & \\checkmark & LC & 18.7 $\\pm$ 0.9 & 47.1 $\\pm$ 1.3 & 28.5 $\\pm$ 1.4 & \\texttt{LLLRLL}, \\texttt{RLLRLL}, \\texttt{RLRRLL} \\\\\n",
      "4-gram PLM & \\checkmark & TD & 29.2 $\\pm$ 0.6 & 40.0 $\\pm$ 1.6 & 4.4 $\\pm$ 5.4 & \\texttt{LLRRRL}, \\texttt{RLRRRL}, \\texttt{LLRRRR} \\\\\n",
      "4-gram PLM & \\checkmark & LC & 21.9 $\\pm$ 0.6 & 50.6 $\\pm$ 0.6 & 22.0 $\\pm$ 0.9 & \\texttt{RLLRLL}, \\texttt{RLRRLL}, \\texttt{LLLRLL} \\\\\n",
      "3-gram PLM & \\checkmark & TD & 19.9 $\\pm$ 0.7 & 29.0 $\\pm$ 1.8 & 17.3 $\\pm$ 2.0 & \\texttt{RLLRRL}, \\texttt{LLLRRL}, \\texttt{RLLRRR} \\\\\n",
      "3-gram PLM & \\checkmark & LC & 18.2 $\\pm$ 0.2 & 55.6 $\\pm$ 0.3 & 26.9 $\\pm$ 0.5 & \\texttt{RLLRRR}, \\texttt{RLLRRL}, \\texttt{RLRRRR} \\\\\n",
      "RNNG & & TD & -22.6 $\\pm$ 4.7 & 6.0 $\\pm$ 14.5 & 14.5 $\\pm$ 10.8 & \\texttt{RLLRLL}, \\texttt{RRRRLL}, \\texttt{RRRLLL} \\\\\n",
      "RNNG & & LC & -17.6 $\\pm$ 6.4 & 25.1 $\\pm$ 13.4 & -21.2 $\\pm$ 2.0 & \\texttt{RRRRRL}, \\texttt{RRLLRL}, \\texttt{RRLRRL} \\\\\n",
      "SRNNG & \\checkmark & TD & 2.1 $\\pm$ 9.3 & 10.7 $\\pm$ 7.8 & 10.2 $\\pm$ 7.0 & \\texttt{RLLRRR}, \\texttt{RLRRRR}, \\texttt{RLLRRL} \\\\\n",
      "SRNNG & \\checkmark & LC & 19.0 $\\pm$ 9.5 & 23.7 $\\pm$ 12.9 & -40.4 $\\pm$ 8.5 & \\texttt{LRRRRR}, \\texttt{LRLRRR}, \\texttt{LLLRRR} \\\\\n",
      "Stack depth & & TD & -47.6 $\\pm$ 0.2 & -12.0 $\\pm$ 0.6 & -56.2 $\\pm$ 1.3 & \\texttt{RRLRRR}, \\texttt{RRLLRR}, \\texttt{RRRRRR} \\\\\n",
      "Stack depth & & LC & -14.5 $\\pm$ 0.9 & -4.1 $\\pm$ 0.7 & 57.4 $\\pm$ 1.8 & \\texttt{RLLLLL}, \\texttt{RLLRLL}, \\texttt{RLRLLL} \\\\\n",
      "LLaMA2 (7B) & &  & 6.9 $\\pm$ 31.0 & 15.5 $\\pm$ 2.5 & -4.8 $\\pm$ 31.0 & \\texttt{LRLLLL}, \\texttt{LRRLLL}, \\texttt{LRLRLL} \\\\\n",
      "\\multicolumn{9}{c}{PPL$^3$} \\\\\n",
      "Transformer & & & 11.1 $\\pm$ 4.3 & 16.3 $\\pm$ 6.4 & 22.5 $\\pm$ 6.1 & \\texttt{LLLLLL}, \\texttt{LLRLLL}, \\texttt{RLRLLL} \\\\\n",
      "LSTM & \\textcolor{gray}{\\checkmark} & & 9.2 $\\pm$ 14.7 & 26.4 $\\pm$ 7.4 & -2.3 $\\pm$ 11.3 & \\texttt{RLRLLL}, \\texttt{RLLLLL}, \\texttt{RRRRRR} \\\\\n",
      "SRN  & \\checkmark & & 16.1 $\\pm$ 9.4 & 38.3 $\\pm$ 3.0 & -3.5 $\\pm$ 10.4 & \\texttt{RLLLLL}, \\texttt{RLRLLL}, \\texttt{RLRRLL} \\\\\n",
      "Word 5-gram & \\checkmark & & 5.3 $\\pm$ 1.0 & 16.3 $\\pm$ 1.7 & -4.8 $\\pm$ 1.6 & \\texttt{RRLRRR}, \\texttt{RRRRRR}, \\texttt{LRLRRR} \\\\\n",
      "Word 4-gram & \\checkmark & & 6.3 $\\pm$ 1.0 & 15.7 $\\pm$ 1.6 & -5.3 $\\pm$ 1.6 & \\texttt{RRLRRR}, \\texttt{RRRRRR}, \\texttt{LRLRRR} \\\\\n",
      "Word 3-gram & \\checkmark & & 8.3 $\\pm$ 0.7 & 16.8 $\\pm$ 1.0 & -5.1 $\\pm$ 1.0 & \\texttt{RRRRRR}, \\texttt{RRLRRR}, \\texttt{LRLRRR} \\\\\n",
      "Trans. PLM & & TD & 30.2 $\\pm$ 5.7 & 29.9 $\\pm$ 9.1 & 34.7 $\\pm$ 4.7 & \\texttt{LLRRLL}, \\texttt{LLRRRL}, \\texttt{LLRLLL} \\\\\n",
      "Trans. PLM & & LC & 30.3 $\\pm$ 2.1 & 42.6 $\\pm$ 1.1 & 33.0 $\\pm$ 2.3 & \\texttt{LLLLLL}, \\texttt{LLRLLL}, \\texttt{LLRRLL} \\\\\n",
      "LSTM PLM & \\textcolor{gray}{\\checkmark} & TD & 11.8 $\\pm$ 12.2 & 36.9 $\\pm$ 7.3 & -27.0 $\\pm$ 10.5 & \\texttt{LRRRRL}, \\texttt{LRLRRL}, \\texttt{LRRRRR} \\\\\n",
      "LSTM PLM & \\textcolor{gray}{\\checkmark} & LC & 23.6 $\\pm$ 3.6 & 40.3 $\\pm$ 2.5 & 0.2 $\\pm$ 5.5 & \\texttt{RLLRRR}, \\texttt{LLLLLL}, \\texttt{LLLRLL} \\\\\n",
      "SRN PLM & \\checkmark & TD & -5.7 $\\pm$ 8.3 & 8.6 $\\pm$ 7.8 & -53.6 $\\pm$ 7.4 & \\texttt{RLRRRR}, \\texttt{LRLRRR}, \\texttt{RLLRRR} \\\\\n",
      "SRN PLM & \\checkmark & LC & 10.2 $\\pm$ 4.9 & 27.3 $\\pm$ 10.5 & 2.7 $\\pm$ 5.2 & \\texttt{RLRRLL}, \\texttt{RLRRRR}, \\texttt{RLLRLL} \\\\\n",
      "5-gram PLM & \\checkmark & TD & 11.9 $\\pm$ 2.4 & 50.3 $\\pm$ 2.8 & 10.1 $\\pm$ 7.8 & \\texttt{RLLRRL}, \\texttt{RLRRRL}, \\texttt{RLLLLL} \\\\\n",
      "5-gram PLM & \\checkmark & LC & 18.8 $\\pm$ 0.9 & 47.2 $\\pm$ 1.3 & 28.2 $\\pm$ 1.4 & \\texttt{LLLRLL}, \\texttt{RLLRLL}, \\texttt{RLRRLL} \\\\\n",
      "4-gram PLM & \\checkmark & TD & 29.2 $\\pm$ 0.6 & 40.0 $\\pm$ 1.6 & 4.5 $\\pm$ 5.4 & \\texttt{LLRRRL}, \\texttt{RLRRRL}, \\texttt{LLRRRR} \\\\\n",
      "4-gram PLM & \\checkmark & LC & 22.1 $\\pm$ 0.6 & 50.6 $\\pm$ 0.6 & 21.7 $\\pm$ 0.9 & \\texttt{RLLRLL}, \\texttt{RLRRLL}, \\texttt{LLLRLL} \\\\\n",
      "3-gram PLM & \\checkmark & TD & 19.9 $\\pm$ 0.7 & 29.0 $\\pm$ 1.8 & 17.4 $\\pm$ 2.0 & \\texttt{RLLRRL}, \\texttt{LLLRRL}, \\texttt{RLLRRR} \\\\\n",
      "3-gram PLM & \\checkmark & LC & 18.4 $\\pm$ 0.2 & 55.6 $\\pm$ 0.3 & 26.8 $\\pm$ 0.5 & \\texttt{RLLRRR}, \\texttt{RLLRRL}, \\texttt{RLRRRR} \\\\\n",
      "RNNG & & TD & -22.5 $\\pm$ 4.7 & 6.0 $\\pm$ 14.5 & 14.5 $\\pm$ 10.8 & \\texttt{RLLRLL}, \\texttt{RRRRLL}, \\texttt{RRRLLL} \\\\\n",
      "RNNG & & LC & -17.6 $\\pm$ 6.4 & 25.1 $\\pm$ 13.4 & -21.2 $\\pm$ 2.0 & \\texttt{RRRRRL}, \\texttt{RRLLRL}, \\texttt{RRLRRL} \\\\\n",
      "SRNNG & \\checkmark & TD & 2.2 $\\pm$ 9.3 & 10.7 $\\pm$ 7.8 & 10.2 $\\pm$ 7.0 & \\texttt{RLLRRR}, \\texttt{RLRRRR}, \\texttt{RLLRRL} \\\\\n",
      "SRNNG & \\checkmark & LC & 19.0 $\\pm$ 9.5 & 23.6 $\\pm$ 12.9 & -40.2 $\\pm$ 8.5 & \\texttt{LRRRRR}, \\texttt{LRLRRR}, \\texttt{LLLRRR} \\\\\n",
      "Stack depth & & TD & -47.7 $\\pm$ 0.2 & -12.0 $\\pm$ 0.6 & -56.2 $\\pm$ 1.3 & \\texttt{RRLRRR}, \\texttt{RRLLRR}, \\texttt{RRRRRR} \\\\\n",
      "Stack depth & & LC & -15.9 $\\pm$ 0.9 & -3.9 $\\pm$ 0.7 & 56.3 $\\pm$ 1.8 & \\texttt{RLLLLL}, \\texttt{RLLRLL}, \\texttt{RLRLLL} \\\\\n",
      "LLaMA2 (7B) & &  & 6.9 $\\pm$ 31.0 & 15.5 $\\pm$ 2.5 & -4.9 $\\pm$ 31.0 & \\texttt{LRLLLL}, \\texttt{LRRLLL}, \\texttt{LRLRLL} \\\\\n",
      "\\multicolumn{9}{c}{log(PPL)} \\\\\n",
      "Transformer & & & 12.6 $\\pm$ 4.3 & 16.8 $\\pm$ 6.4 & 24.4 $\\pm$ 6.1 & \\texttt{LLLLLL}, \\texttt{LLRLLL}, \\texttt{RLRLLL} \\\\\n",
      "LSTM & \\textcolor{gray}{\\checkmark} & & 11.8 $\\pm$ 14.7 & 27.2 $\\pm$ 7.4 & -0.4 $\\pm$ 11.3 & \\texttt{RLRLLL}, \\texttt{RLLLLL}, \\texttt{RRRRRR} \\\\\n",
      "SRN  & \\checkmark & & 16.7 $\\pm$ 9.4 & 38.4 $\\pm$ 3.0 & -3.5 $\\pm$ 10.4 & \\texttt{RLLLLL}, \\texttt{RLRLLL}, \\texttt{RLRRLL} \\\\\n",
      "Word 5-gram & \\checkmark & & 5.5 $\\pm$ 1.0 & 17.3 $\\pm$ 1.7 & -6.3 $\\pm$ 1.6 & \\texttt{RRLRRR}, \\texttt{RRRRRR}, \\texttt{LRLRRR} \\\\\n",
      "Word 4-gram & \\checkmark & & 6.7 $\\pm$ 1.0 & 16.8 $\\pm$ 1.6 & -7.0 $\\pm$ 1.6 & \\texttt{RRLRRR}, \\texttt{RRRRRR}, \\texttt{LRLRRR} \\\\\n",
      "Word 3-gram & \\checkmark & & 9.0 $\\pm$ 0.7 & 17.9 $\\pm$ 1.0 & -6.6 $\\pm$ 1.0 & \\texttt{RRRRRR}, \\texttt{RRLRRR}, \\texttt{LRLRRR} \\\\\n",
      "Trans. PLM & & TD & 30.5 $\\pm$ 5.7 & 29.4 $\\pm$ 9.1 & 36.5 $\\pm$ 4.7 & \\texttt{LLRRLL}, \\texttt{LLRRRL}, \\texttt{LLRLLL} \\\\\n",
      "Trans. PLM & & LC & 30.2 $\\pm$ 2.1 & 42.2 $\\pm$ 1.1 & 36.2 $\\pm$ 2.3 & \\texttt{LLLLLL}, \\texttt{LLRLLL}, \\texttt{LLRRLL} \\\\\n",
      "LSTM PLM & \\textcolor{gray}{\\checkmark} & TD & 12.0 $\\pm$ 12.2 & 37.1 $\\pm$ 7.3 & -27.2 $\\pm$ 10.5 & \\texttt{LRRRRL}, \\texttt{LRLRRL}, \\texttt{LRRRRR} \\\\\n",
      "LSTM PLM & \\textcolor{gray}{\\checkmark} & LC & 23.6 $\\pm$ 3.6 & 40.4 $\\pm$ 2.5 & 0.7 $\\pm$ 5.5 & \\texttt{RLLRRR}, \\texttt{LLLLLL}, \\texttt{LLLRLL} \\\\\n",
      "SRN PLM & \\checkmark & TD & -5.3 $\\pm$ 8.3 & 8.8 $\\pm$ 7.8 & -53.8 $\\pm$ 7.4 & \\texttt{RLRRRR}, \\texttt{LRLRRR}, \\texttt{RLLRRR} \\\\\n",
      "SRN PLM & \\checkmark & LC & 9.1 $\\pm$ 4.9 & 27.6 $\\pm$ 10.5 & 2.8 $\\pm$ 5.2 & \\texttt{RLRRLL}, \\texttt{RLRRRR}, \\texttt{RLLRLL} \\\\\n",
      "5-gram PLM & \\checkmark & TD & 11.8 $\\pm$ 2.4 & 50.5 $\\pm$ 2.8 & 10.2 $\\pm$ 7.8 & \\texttt{RLLRRL}, \\texttt{RLRRRL}, \\texttt{RLLLLL} \\\\\n",
      "5-gram PLM & \\checkmark & LC & 18.4 $\\pm$ 0.9 & 46.9 $\\pm$ 1.3 & 29.1 $\\pm$ 1.4 & \\texttt{LLLRLL}, \\texttt{RLLRLL}, \\texttt{RLRRLL} \\\\\n",
      "4-gram PLM & \\checkmark & TD & 29.2 $\\pm$ 0.6 & 40.0 $\\pm$ 1.6 & 4.3 $\\pm$ 5.4 & \\texttt{LLRRRL}, \\texttt{RLRRRL}, \\texttt{LLRRRR} \\\\\n",
      "4-gram PLM & \\checkmark & LC & 21.5 $\\pm$ 0.6 & 50.5 $\\pm$ 0.6 & 22.5 $\\pm$ 0.9 & \\texttt{RLLRLL}, \\texttt{RLRRLL}, \\texttt{LLLRLL} \\\\\n",
      "3-gram PLM & \\checkmark & TD & 19.9 $\\pm$ 0.7 & 29.0 $\\pm$ 1.8 & 17.2 $\\pm$ 2.0 & \\texttt{RLLRRL}, \\texttt{LLLRRL}, \\texttt{RLLRRR} \\\\\n",
      "3-gram PLM & \\checkmark & LC & 17.8 $\\pm$ 0.2 & 55.7 $\\pm$ 0.3 & 27.0 $\\pm$ 0.5 & \\texttt{RLLRRR}, \\texttt{RLLRRL}, \\texttt{RLRRRR} \\\\\n",
      "RNNG & & TD & -22.7 $\\pm$ 4.7 & 6.0 $\\pm$ 14.5 & 14.5 $\\pm$ 10.8 & \\texttt{RLLRLL}, \\texttt{RRRRLL}, \\texttt{RRRLLL} \\\\\n",
      "RNNG & & LC & -17.6 $\\pm$ 6.4 & 25.1 $\\pm$ 13.4 & -21.1 $\\pm$ 2.0 & \\texttt{RRRRRL}, \\texttt{RRLLRL}, \\texttt{RRLRRL} \\\\\n",
      "SRNNG & \\checkmark & TD & 1.8 $\\pm$ 9.3 & 10.7 $\\pm$ 7.8 & 10.1 $\\pm$ 7.0 & \\texttt{RLLRRR}, \\texttt{RLRRRR}, \\texttt{RLLRRL} \\\\\n",
      "SRNNG & \\checkmark & LC & 19.2 $\\pm$ 9.5 & 23.8 $\\pm$ 12.9 & -40.7 $\\pm$ 8.5 & \\texttt{LRRRRR}, \\texttt{LRLRRR}, \\texttt{LLLRRR} \\\\\n",
      "Stack depth & & TD & -47.4 $\\pm$ 0.2 & -12.1 $\\pm$ 0.6 & -56.2 $\\pm$ 1.3 & \\texttt{RRLRRR}, \\texttt{RRLLRR}, \\texttt{RRRRRR} \\\\\n",
      "Stack depth & & LC & -11.7 $\\pm$ 0.9 & -4.6 $\\pm$ 0.7 & 57.3 $\\pm$ 1.8 & \\texttt{RLLLLL}, \\texttt{RLLRLL}, \\texttt{RLRLLL} \\\\\n",
      "LLaMA2 (7B) & &  & 6.8 $\\pm$ 31.0 & 15.4 $\\pm$ 2.5 & -4.5 $\\pm$ 31.0 & \\texttt{LRLLLL}, \\texttt{LRRLLL}, \\texttt{LRLRLL} \\\\\n"
     ]
    }
   ],
   "source": [
    "for k in ks:\n",
    "    print(\"\\multicolumn{9}{c}{\" + k2label[k] + \"} \\\\\\\\\")\n",
    "    for score, std, top3 in zip(df[df[\"k\"]==k][metrics].groupby(\"model\").mean().reindex(model_order).iterrows(), df[df[\"k\"]==\"1.0\"][metrics].groupby(\"model\").std().reindex(model_order).iterrows(), df[(df[\"k\"]==\"1.0\") & (df[\"fold\"]==0)][[\"model\", \"top3_langs\"]].set_index(\"model\").loc[model_order][\"top3_langs\"].apply(lambda x: \", \".join([\"\\\\texttt{\" + l.replace(\"'\", \"\").strip(\"[] \").replace(\"1\", \"R\").replace(\"0\", \"L\").replace(\"X\", \"\") + \"}\" for l in x.split(\",\")]))):\n",
    "        model = score[0]\n",
    "        if model in model2name:\n",
    "            model = model2name[model]\n",
    "        print(f\"{model} & {score[1]['correl']*100:.1f} $\\pm$ {std[1]['correl']*100:.1f} & {score[1]['micro_correl']*100:.1f} $\\pm$ {std[1]['micro_correl']*100:.1f} & {score[1]['left_pref']*100:.1f} $\\pm$ {std[1]['left_pref']*100:.1f} & {top3} \\\\\\\\\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parseability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNNG_top_down_beam & -2.5 $\\pm$ 1.1 & 26.5 $\\pm$ 2.5 & 24.9 $\\pm$ 2.4 & \\texttt{RLRLLL}, \\texttt{RLLLLL}, \\texttt{RLLRLL} \\\\\n",
      "SRNNG_top_down_beam & -6.5 $\\pm$ 2.2 & 14.0 $\\pm$ 1.5 & 22.6 $\\pm$ 7.1 & \\texttt{RLRLLL}, \\texttt{RLRRLL}, \\texttt{RLLRLL} \\\\\n",
      "RNNG_in_order_beam & 10.1 $\\pm$ 6.5 & 17.1 $\\pm$ 3.0 & -19.7 $\\pm$ 10.0 & \\texttt{LRRRLL}, \\texttt{RRRRRR}, \\texttt{RRRLRR} \\\\\n",
      "SRNNG_in_order_beam & 8.2 $\\pm$ 3.1 & -12.5 $\\pm$ 1.8 & -20.6 $\\pm$ 8.6 & \\texttt{RRRRRR}, \\texttt{RRRLRR}, \\texttt{RRLRRR} \\\\\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../work/results/regression/results_20230927_parseability.csv\")\n",
    "model_rnngs = [\"RNNG_top_down_beam\", \"SRNNG_top_down_beam\", \"RNNG_in_order_beam\", \"SRNNG_in_order_beam\"]\n",
    "\n",
    "for score, std, top3 in zip(df[(df[\"k\"]==\"1.0\")][metrics].groupby(\"model\").mean().reindex(model_rnngs).iterrows(), df[df[\"k\"]==\"1.0\"][metrics].groupby(\"model\").std().reindex(model_rnngs).iterrows(), df[(df[\"k\"]==\"1.0\") & (df[\"fold\"]==0)][[\"model\", \"top3_langs\"]].set_index(\"model\").loc[model_rnngs][\"top3_langs\"].apply(lambda x: \", \".join([\"\\\\texttt{\" + l.replace(\"'\", \"\").strip(\"[] \").replace(\"1\", \"R\").replace(\"0\", \"L\").replace(\"X\", \"\") + \"}\" for l in x.split(\",\")]))):\n",
    "    model = score[0]\n",
    "    if model in model2name:\n",
    "        model = model2name[model]\n",
    "    print(f\"{model} & {score[1]['correl']*100:.1f} $\\pm$ {std[1]['correl']*100:.1f} & {score[1]['micro_correl']*100:.1f} $\\pm$ {std[1]['micro_correl']*100:.1f} & {score[1]['left_pref']*100:.1f} $\\pm$ {std[1]['left_pref']*100:.1f} & {top3} \\\\\\\\\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parseability and predictability test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3677686386527389\n",
      "0.2930154839690427\n",
      "0.1642837553774918\n",
      "0.36302292764955457\n",
      "0.8254732376117565\n",
      "0.1570928885548097\n",
      "0.6178976030214567\n",
      "0.49198466523333784\n",
      "0.16364639083178073\n",
      "0.7365362655898203\n",
      "0.7720757054796396\n",
      "0.5330888155828633\n",
      "0.7320142456921206\n",
      "0.8670084955117991\n",
      "0.37790288524291127\n",
      "0.400506280333491\n",
      "0.5780045715161701\n",
      "0.4330922122971129\n",
      "0.27297968225974256\n",
      "0.5570287598275236\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../work/results/regression/results_20230927_parseability_predictability.csv\")\n",
    "for i in df[\"delta loglik\"]:\n",
    "    print(chi2.sf(i*2, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNNG & TD & & & -22.6 $\\pm$ 4.7 & 6.0 $\\pm$ 14.5  & 14.5 $\\pm$ 10.8 & \\texttt{RLLRLL}, \\texttt{RRRRLL}, \\texttt{RRRLLL} \\\\\n",
      "SRNNG & TD & \\checkmark & & 2.0 $\\pm$ 9.3 & 10.7 $\\pm$ 7.8  & 10.2 $\\pm$ 7.0 & \\texttt{RLLRLL}, \\texttt{RRRRLL}, \\texttt{RRRLLL} \\\\\n",
      "RNNG & LC & & & -17.6 $\\pm$ 6.4 & 25.1 $\\pm$ 13.4  & -21.2 $\\pm$ 2.0 & \\texttt{RLLRLL}, \\texttt{RRRRLL}, \\texttt{RRRLLL} \\\\\n",
      "SRNNG & LC & \\checkmark & & 19.1 $\\pm$ 9.5 & 23.7 $\\pm$ 12.9  & -40.6 $\\pm$ 8.5 & \\texttt{RLLRLL}, \\texttt{RRRRLL}, \\texttt{RRRLLL} \\\\\n",
      "RNNG & TD & & \\checkmark & 9.4 $\\pm$ 3.5 & -31.5 $\\pm$ 11.6  & -30.1 $\\pm$ 5.7 & \\texttt{RLLRLL}, \\texttt{RRRRLL}, \\texttt{RRRLLL} \\\\\n",
      "SRNNG & TD & \\checkmark & \\checkmark & 14.6 $\\pm$ 8.7 & -2.8 $\\pm$ 5.9  & -21.5 $\\pm$ 8.9 & \\texttt{RLLRRR}, \\texttt{RLRRRR}, \\texttt{RLLRRL} \\\\\n",
      "RNNG & LC & & \\checkmark & -23.4 $\\pm$ 7.0 & 26.5 $\\pm$ 13.9  & -26.2 $\\pm$ 7.2 & \\texttt{RLLRRR}, \\texttt{RLRRRR}, \\texttt{RLLRRL} \\\\\n",
      "SRNNG & LC & \\checkmark & \\checkmark & 17.2 $\\pm$ 8.5 & 18.3 $\\pm$ 12.4  & -36.7 $\\pm$ 9.7 & \\texttt{RLLRRR}, \\texttt{RLRRRR}, \\texttt{RLLRRL} \\\\\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../work/results/regression/results_20230908.csv\")\n",
    "\n",
    "model_rnngs = [\"RNNG_top_down\", \"SRNNG_top_down\", \"RNNG_in_order\", \"SRNNG_in_order\",\n",
    "               \"RNNG_top_down_beam\", \"SRNNG_top_down_beam\", \"RNNG_in_order_beam\", \"SRNNG_in_order_beam\"]\n",
    "\n",
    "rnng2name = {\n",
    "    \"RNNG_top_down\": \"RNNG & TD & &\",\n",
    "    \"SRNNG_top_down\": \"SRNNG & TD & \\checkmark &\",\n",
    "    \"RNNG_in_order\": \"RNNG & LC & &\",\n",
    "    \"SRNNG_in_order\": \"SRNNG & LC & \\checkmark &\",\n",
    "    \"RNNG_top_down_beam\": \"RNNG & TD & & \\checkmark\",\n",
    "    \"SRNNG_top_down_beam\": \"SRNNG & TD & \\checkmark & \\checkmark\",\n",
    "    \"RNNG_in_order_beam\": \"RNNG & LC & & \\checkmark\",\n",
    "    \"SRNNG_in_order_beam\": \"SRNNG & LC & \\checkmark & \\checkmark\",\n",
    "}\n",
    "\n",
    "for score, std, top3 in zip(df[df[\"k\"]==\"1.0\"][metrics].groupby(\"model\").mean().reindex(model_rnngs).iterrows(), df[df[\"k\"]==\"1.0\"][metrics].groupby(\"model\").std().reindex(model_rnngs).iterrows(), df[df[\"fold\"]==0][[\"model\", \"top3_langs\"]].set_index(\"model\").loc[model_rnngs][\"top3_langs\"].apply(lambda x: \", \".join([\"\\\\texttt{\" + l.replace(\"'\", \"\").strip(\"[] \").replace(\"1\", \"R\").replace(\"0\", \"L\").replace(\"X\", \"\") + \"}\" for l in x.split(\",\")]))):\n",
    "    model = score[0]\n",
    "    if model in rnng2name:\n",
    "        model = rnng2name[model]\n",
    "    print(f\"{model} & {score[1]['correl']*100:.1f} $\\pm$ {std[1]['correl']*100:.1f} & {score[1]['micro_correl']*100:.1f} $\\pm$ {std[1]['micro_correl']*100:.1f}  & {score[1]['left_pref']*100:.1f} $\\pm$ {std[1]['left_pref']*100:.1f} & {top3} \\\\\\\\\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2architecture = {\n",
    "    \"Transformer\": \"Transformer\",\n",
    "    \"LSTM\": \"LSTM\",\n",
    "    \"RNN\": \"SRN\",\n",
    "    \"3gram\": \"3-gram\",\n",
    "    \"4gram\": \"4-gram\",\n",
    "    \"5gram\": \"5-gram\",\n",
    "    \"Transformer-action_td\": \"Transformer\",\n",
    "    \"Transformer-action_lc-as\": \"Transformer\",\n",
    "    \"LSTM-action_td\":  \"LSTM\",\n",
    "    \"LSTM-action_lc-as\": \"LSTM\",\n",
    "    \"RNN-action_td\": \"SRN\",\n",
    "    \"RNN-action_lc-as\": \"SRN\",\n",
    "    \"5gram_actions_td\": \"5-gram\",\n",
    "    \"4gram_actions_td\": \"4-gram\",\n",
    "    \"3gram_actions_td\": \"3-gram\",\n",
    "    \"5gram_actions_lc-as\": \"5-gram\",\n",
    "    \"4gram_actions_lc-as\": \"4-gram\",\n",
    "    \"3gram_actions_lc-as\": \"3-gram\",\n",
    "    \"RNNG_top_down\": \"RNNG\",\n",
    "    \"SRNNG_top_down\": \"SRNNG\",\n",
    "    \"RNNG_in_order\": \"RNNG\",\n",
    "    \"SRNNG_in_order\": \"SRNNG\",\n",
    "    \"llama2-7b\": \"LLaMA 2\",\n",
    "    \"td\": \"Stack\",\n",
    "    \"lc-as\": \"Stack\",\n",
    "}\n",
    "\n",
    "model2syntax = {\n",
    "    \"Transformer\": False,\n",
    "    \"LSTM\": False,\n",
    "    \"RNN\": False,\n",
    "    \"5gram\": False,\n",
    "    \"4gram\": False,\n",
    "    \"3gram\": False,\n",
    "    \"Transformer-action_td\": True,\n",
    "    \"Transformer-action_lc-as\":  True,\n",
    "    \"LSTM-action_td\": True,\n",
    "    \"LSTM-action_lc-as\": True,\n",
    "    \"RNN-action_td\": True,\n",
    "    \"RNN-action_lc-as\": True,\n",
    "    \"5gram_actions_td\": True,\n",
    "    \"5gram_actions_lc-as\": True,\n",
    "    \"4gram_actions_td\": True,\n",
    "    \"4gram_actions_lc-as\": True,\n",
    "    \"3gram_actions_td\": True,\n",
    "    \"3gram_actions_lc-as\": True,\n",
    "    \"RNNG_top_down\": True,\n",
    "    \"SRNNG_top_down\": True,\n",
    "    \"RNNG_in_order\": True,\n",
    "    \"SRNNG_in_order\": True,\n",
    "}\n",
    "\n",
    "model2traversal = {\n",
    "    \"Transformer\": \"No\",\n",
    "    \"LSTM\": \"No\",\n",
    "    \"RNN\": \"No\",\n",
    "    \"3gram\": \"No\",\n",
    "    \"4gram\": \"No\",\n",
    "    \"5gram\": \"No\",\n",
    "    \"Transformer-action_td\": \"TD\",\n",
    "    \"Transformer-action_lc-as\": \"LC\",\n",
    "    \"LSTM-action_td\": \"TD\",\n",
    "    \"LSTM-action_lc-as\": \"LC\",\n",
    "    \"RNN-action_td\": \"TD\",\n",
    "    \"RNN-action_lc-as\": \"LC\",\n",
    "    \"5gram_actions_td\": \"TD\",\n",
    "    \"4gram_actions_td\": \"TD\",\n",
    "    \"3gram_actions_td\": \"TD\",\n",
    "    \"5gram_actions_lc-as\": \"LC\",\n",
    "    \"4gram_actions_lc-as\": \"LC\",\n",
    "    \"3gram_actions_lc-as\": \"LC\",\n",
    "    \"RNNG_top_down\": \"TD\",\n",
    "    \"SRNNG_top_down\": \"TD\",\n",
    "    \"RNNG_in_order\": \"LC\",\n",
    "    \"SRNNG_in_order\": \"LC\",\n",
    "    \"td\": \"TD\",\n",
    "    \"lc-as\": \"LC\",\n",
    "}\n",
    "\n",
    "model2memory = {\n",
    "    \"Transformer\": 1,\n",
    "    \"LSTM\": 2,\n",
    "    \"RNN\": 3,\n",
    "    \"3gram\": 3,\n",
    "    \"4gram\": 2,\n",
    "    \"5gram\": 1,\n",
    "    \"Transformer-action_td\": 1,\n",
    "    \"Transformer-action_lc-as\": 1,\n",
    "    \"LSTM-action_td\": 2,\n",
    "    \"LSTM-action_lc-as\": 2,\n",
    "    \"RNN-action_td\": 3,\n",
    "    \"RNN-action_lc-as\": 3,\n",
    "    \"5gram_actions_td\": 1,\n",
    "    \"4gram_actions_td\": 2,\n",
    "    \"3gram_actions_td\": 3,\n",
    "    \"5gram_actions_lc-as\": 1,\n",
    "    \"4gram_actions_lc-as\": 2,\n",
    "    \"3gram_actions_lc-as\": 3,\n",
    "    \"RNNG_top_down\": 1,\n",
    "    \"SRNNG_top_down\":2,\n",
    "    \"RNNG_in_order\": 1,\n",
    "    \"SRNNG_in_order\": 2,\n",
    "}\n",
    "\n",
    "model2neural = {\n",
    "    \"Transformer\": 1,\n",
    "    \"LSTM\": 1,\n",
    "    \"RNN\": 1,\n",
    "    \"3gram\": 0,\n",
    "    \"4gram\": 0,\n",
    "    \"5gram\": 0,\n",
    "    \"Transformer-action_td\": 1,\n",
    "    \"Transformer-action_lc-as\": 1,\n",
    "    \"LSTM-action_td\": 1,\n",
    "    \"LSTM-action_lc-as\": 1,\n",
    "    \"RNN-action_td\": 1,\n",
    "    \"RNN-action_lc-as\": 1,\n",
    "    \"5gram_actions_td\": 0,\n",
    "    \"4gram_actions_td\": 0,\n",
    "    \"3gram_actions_td\": 0,\n",
    "    \"5gram_actions_lc-as\": 0,\n",
    "    \"4gram_actions_lc-as\": 0,\n",
    "    \"3gram_actions_lc-as\": 0,\n",
    "    \"RNNG_top_down\": 1,\n",
    "    \"SRNNG_top_down\":1,\n",
    "    \"RNNG_in_order\": 1,\n",
    "    \"SRNNG_in_order\": 1,\n",
    "}\n",
    "\n",
    "model2class = {\n",
    "    \"Transformer\": \"NLM\",\n",
    "    \"LSTM\": \"NLM\",\n",
    "    \"RNN\": \"NLM\",\n",
    "    \"3gram\": \"CLM\",\n",
    "    \"4gram\": \"CLM\",\n",
    "    \"5gram\": \"CLM\",\n",
    "    \"Transformer-action_td\": \"NLM\",\n",
    "    \"Transformer-action_lc-as\": \"NLM\",\n",
    "    \"LSTM-action_td\": \"NLM\",\n",
    "    \"LSTM-action_lc-as\": \"NLM\",\n",
    "    \"RNN-action_td\": \"NLM\",\n",
    "    \"RNN-action_lc-as\": \"NLM\",\n",
    "    \"5gram_actions_td\": \"CLM\",\n",
    "    \"4gram_actions_td\": \"CLM\",\n",
    "    \"3gram_actions_td\": \"CLM\",\n",
    "    \"5gram_actions_lc-as\": \"CLM\",\n",
    "    \"4gram_actions_lc-as\": \"CLM\",\n",
    "    \"3gram_actions_lc-as\": \"CLM\",\n",
    "    \"RNNG_top_down\": \"RNNG\",\n",
    "    \"SRNNG_top_down\":  \"RNNG\",\n",
    "    \"RNNG_in_order\": \"RNNG\",\n",
    "    \"SRNNG_in_order\":  \"RNNG\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer  & NLM & 1 & False & - \\\\\n",
      "LSTM  & NLM & 2 & False & - \\\\\n",
      "SRN   & NLM & 3 & False & - \\\\\n",
      "Word 5-gram  & CLM & 1 & False & - \\\\\n",
      "Word 4-gram  & CLM & 2 & False & - \\\\\n",
      "Word 3-gram  & CLM & 3 & False & - \\\\\n",
      "Trans. PLM  & NLM & 1 & True & TD \\\\\n",
      "Trans. PLM  & NLM & 1 & True & LC \\\\\n",
      "LSTM PLM  & NLM & 2 & True & TD \\\\\n",
      "LSTM PLM  & NLM & 2 & True & LC \\\\\n",
      "SRN PLM  & NLM & 3 & True & TD \\\\\n",
      "SRN PLM  & NLM & 3 & True & LC \\\\\n",
      "5-gram PLM  & CLM & 1 & True & TD \\\\\n",
      "5-gram PLM  & CLM & 1 & True & LC \\\\\n",
      "4-gram PLM  & CLM & 2 & True & TD \\\\\n",
      "4-gram PLM  & CLM & 2 & True & LC \\\\\n",
      "3-gram PLM  & CLM & 3 & True & TD \\\\\n",
      "3-gram PLM  & CLM & 3 & True & LC \\\\\n",
      "RNNG  & RNNG & 1 & True & TD \\\\\n",
      "RNNG  & RNNG & 1 & True & LC \\\\\n",
      "SRNNG  & RNNG & 2 & True & TD \\\\\n",
      "SRNNG  & RNNG & 2 & True & LC \\\\\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../work/results/regression/results_20230908.csv\")\n",
    "df = df[df[\"k\"]==\"1.0\"]\n",
    "df_stack = pd.read_csv(\"../work/results/regression/results_20231217_stack_depth.csv\")\n",
    "df_stack = df_stack[df_stack[\"k\"]==\"1.0\"]\n",
    "df = pd.concat([df, df_stack])\n",
    "\n",
    "df[\"architecture\"] = df[\"model\"].map(model2architecture)\n",
    "df[\"syntax\"] = df[\"model\"].map(model2syntax)\n",
    "df[\"traversal\"] = df[\"model\"].map(model2traversal)\n",
    "df[\"memory\"] = df[\"model\"].map(model2memory)\n",
    "df[\"neural\"] = df[\"model\"].map(model2neural)\n",
    "df[\"class\"] = df[\"model\"].map(model2class)\n",
    "df_sub = df[df[\"model\"].isin(list(model2syntax.keys()))]\n",
    "\n",
    "for row in df_sub[[\"model\", \"class\", \"memory\", \"syntax\", \"traversal\"]].drop_duplicates().set_index(\"model\").reindex(model_order).dropna().iterrows():\n",
    "    print(f\"{model2name[row[0]].split('&')[0]} & {row[1]['class']} & {int(row[1]['memory'])} & {row[1]['syntax']} & {row[1]['traversal'].replace('No', '-')} \\\\\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 correl   R-squared:                       0.378\n",
      "Model:                            OLS   Adj. R-squared:                  0.349\n",
      "Method:                 Least Squares   F-statistic:                     12.67\n",
      "Date:                Wed, 02 Oct 2024   Prob (F-statistic):           1.30e-09\n",
      "Time:                        20:24:37   Log-Likelihood:                 81.940\n",
      "No. Observations:                 110   AIC:                            -151.9\n",
      "Df Residuals:                     104   BIC:                            -135.7\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "========================================================================================\n",
      "                           coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------\n",
      "Intercept                0.0286      0.027      1.062      0.291      -0.025       0.082\n",
      "class_NLM[T.True]        0.0875      0.018      4.847      0.000       0.052       0.123\n",
      "class_CLM[T.True]        0.0882      0.018      4.883      0.000       0.052       0.124\n",
      "class_RNNG[T.True]      -0.1471      0.024     -6.241      0.000      -0.194      -0.100\n",
      "syntax[T.True]           0.0545      0.030      1.844      0.068      -0.004       0.113\n",
      "traversal_LC[T.True]     0.0575      0.026      2.176      0.032       0.005       0.110\n",
      "memory                  -0.0084      0.015     -0.573      0.568      -0.037       0.021\n",
      "==============================================================================\n",
      "Omnibus:                        0.860   Durbin-Watson:                   0.682\n",
      "Prob(Omnibus):                  0.650   Jarque-Bera (JB):                0.418\n",
      "Skew:                           0.017   Prob(JB):                        0.811\n",
      "Kurtosis:                       3.300   Cond. No.                     4.73e+15\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 3.01e-29. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "# Global correlations, all models\n",
    "\n",
    "traversal_dumies = pd.get_dummies(df_sub[\"traversal\"], prefix=\"traversal\")\n",
    "class_dumies = pd.get_dummies(df_sub[\"class\"], prefix=\"class\")\n",
    "X = pd.concat([class_dumies, df_sub, traversal_dumies], axis=1)\n",
    "model = ols('correl ~ class_NLM + class_CLM + class_RNNG + syntax + memory + traversal_LC', data=X).fit()\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 correl   R-squared:                       0.548\n",
      "Model:                            OLS   Adj. R-squared:                  0.518\n",
      "Method:                 Least Squares   F-statistic:                     17.95\n",
      "Date:                Wed, 02 Oct 2024   Prob (F-statistic):           1.29e-11\n",
      "Time:                        20:24:41   Log-Likelihood:                 74.010\n",
      "No. Observations:                  80   AIC:                            -136.0\n",
      "Df Residuals:                      74   BIC:                            -121.7\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "========================================================================================\n",
      "                           coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------\n",
      "Intercept               -0.0643      0.026     -2.472      0.016      -0.116      -0.012\n",
      "class_NLM[T.True]        0.0932      0.026      3.581      0.001       0.041       0.145\n",
      "class_CLM[T.True]        0.0319      0.019      1.715      0.091      -0.005       0.069\n",
      "class_RNNG[T.True]      -0.1894      0.026     -7.278      0.000      -0.241      -0.138\n",
      "syntax[T.True]           0.1102      0.035      3.189      0.002       0.041       0.179\n",
      "traversal_LC[T.True]     0.0390      0.028      1.381      0.171      -0.017       0.095\n",
      "memory                   0.0508      0.015      3.413      0.001       0.021       0.080\n",
      "==============================================================================\n",
      "Omnibus:                        6.538   Durbin-Watson:                   0.995\n",
      "Prob(Omnibus):                  0.038   Jarque-Bera (JB):                9.966\n",
      "Skew:                           0.200   Prob(JB):                      0.00686\n",
      "Kurtosis:                       4.682   Cond. No.                     1.50e+16\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 2.08e-30. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "# Global correlations, without neural PLMs\n",
    "\n",
    "X = X[~((X[\"class_NLM\"]) & (X[\"syntax\"]))]\n",
    "model = ols('correl ~ class_NLM + class_CLM + class_RNNG + syntax + memory + traversal_LC', data=X).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           micro_correl   R-squared:                       0.525\n",
      "Model:                            OLS   Adj. R-squared:                  0.502\n",
      "Method:                 Least Squares   F-statistic:                     23.01\n",
      "Date:                Wed, 02 Oct 2024   Prob (F-statistic):           1.71e-15\n",
      "Time:                        20:24:44   Log-Likelihood:                 89.964\n",
      "No. Observations:                 110   AIC:                            -167.9\n",
      "Df Residuals:                     104   BIC:                            -151.7\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "========================================================================================\n",
      "                           coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------\n",
      "Intercept                0.1374      0.025      5.484      0.000       0.088       0.187\n",
      "class_NLM[T.True]        0.0903      0.017      5.380      0.000       0.057       0.124\n",
      "class_CLM[T.True]        0.1529      0.017      9.107      0.000       0.120       0.186\n",
      "class_RNNG[T.True]      -0.1059      0.022     -4.831      0.000      -0.149      -0.062\n",
      "syntax[T.True]           0.0975      0.027      3.550      0.001       0.043       0.152\n",
      "traversal_LC[T.True]     0.1261      0.025      5.136      0.000       0.077       0.175\n",
      "memory                  -0.0188      0.014     -1.382      0.170      -0.046       0.008\n",
      "==============================================================================\n",
      "Omnibus:                        0.057   Durbin-Watson:                   0.933\n",
      "Prob(Omnibus):                  0.972   Jarque-Bera (JB):                0.103\n",
      "Skew:                           0.052   Prob(JB):                        0.950\n",
      "Kurtosis:                       2.891   Cond. No.                     4.73e+15\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 3.01e-29. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "# Local correlations, all models\n",
    "\n",
    "traversal_dumies = pd.get_dummies(df_sub[\"traversal\"], prefix=\"traversal\")\n",
    "class_dumies = pd.get_dummies(df_sub[\"class\"], prefix=\"class\")\n",
    "X = pd.concat([class_dumies, df_sub, traversal_dumies], axis=1)\n",
    "\n",
    "model = ols('micro_correl ~ class_NLM + class_CLM + class_RNNG + syntax + memory + traversal_LC', data=X).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           micro_correl   R-squared:                       0.739\n",
      "Model:                            OLS   Adj. R-squared:                  0.721\n",
      "Method:                 Least Squares   F-statistic:                     41.90\n",
      "Date:                Sat, 13 Jul 2024   Prob (F-statistic):           2.99e-20\n",
      "Time:                        16:25:40   Log-Likelihood:                 85.216\n",
      "No. Observations:                  80   AIC:                            -158.4\n",
      "Df Residuals:                      74   BIC:                            -144.1\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "========================================================================================\n",
      "                           coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------\n",
      "Intercept                0.0634      0.023      2.803      0.006       0.018       0.108\n",
      "class_NLM[T.True]        0.1847      0.023      8.166      0.000       0.140       0.230\n",
      "class_CLM[T.True]        0.0817      0.016      5.058      0.000       0.050       0.114\n",
      "class_RNNG[T.True]      -0.2030      0.023     -8.976      0.000      -0.248      -0.158\n",
      "syntax[T.True]           0.2188      0.030      7.285      0.000       0.159       0.279\n",
      "traversal_LC[T.True]     0.1318      0.025      5.374      0.000       0.083       0.181\n",
      "memory                   0.0124      0.013      0.956      0.342      -0.013       0.038\n",
      "==============================================================================\n",
      "Omnibus:                        0.731   Durbin-Watson:                   1.438\n",
      "Prob(Omnibus):                  0.694   Jarque-Bera (JB):                0.286\n",
      "Skew:                           0.086   Prob(JB):                        0.867\n",
      "Kurtosis:                       3.237   Cond. No.                     1.50e+16\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 2.08e-30. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "# Local correlations, without neural PLMs\n",
    "\n",
    "X = X[~((X[\"class_NLM\"]) & (X[\"syntax\"]))]\n",
    "model = ols('micro_correl ~ class_NLM + class_CLM + class_RNNG + syntax + memory + traversal_LC', data=X).fit()\n",
    "print(model.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
