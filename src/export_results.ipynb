{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "from collections import defaultdict\n",
    "from statistics import mean\n",
    "\n",
    "\n",
    "def marginalize_complementizer(lang2score):\n",
    "    lang2marginalized_score = defaultdict(list)\n",
    "    for lang, score in lang2score.items():\n",
    "        lang2marginalized_score[lang[:2] + \"X\" + lang[3:]].append(float(score))\n",
    "    lang2score = {}\n",
    "    for lang, scores in lang2marginalized_score.items():\n",
    "        lang2score[lang] = mean(scores)\n",
    "    return lang2score\n",
    "\n",
    "def summarize(dir_path, model_name=\"\", fold=\"\"):\n",
    "    files = glob.glob(dir_path, recursive=True)\n",
    "    lang2ppl = {}\n",
    "    for file in files:\n",
    "        lang = file.split(\"/\")[-3]\n",
    "        with open(file) as f:\n",
    "            ppl = [float(line.split()[1]) for line in f if line.startswith(\"ppl: \")][0]\n",
    "            lang2ppl[lang] = ppl\n",
    "    lang2ppl = marginalize_complementizer(lang2ppl)\n",
    "    json.dump(lang2ppl, open(f\"../work/lang_ppl_distributions/{model_name}_fold{fold}.json\", \"w\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = [\"0\", \"20000\", \"40000\", \"60000\", \"80000\"]\n",
    "for fold in folds:\n",
    "    summarize(f\"../work/tree_per_line/**/{fold}/ngram/tst.subword.3gram.ppl\", \"3gram\", fold)\n",
    "    summarize(f\"../work/tree_per_line/**/{fold}/ngarm/tst.subword.4gram.ppl\", \"4gram\", fold)\n",
    "    summarize(f\"../work/tree_per_line/**/{fold}/ngram/tst.subword.5gram.ppl\", \"5gram\", fold)\n",
    "\n",
    "    summarize(f\"../work/tree_per_line/**/{fold}/td/ngram/tst.actions.subword.3gram.ppl\", \"td_actions_3gram\", fold)\n",
    "    summarize(f\"../work/tree_per_line/**/{fold}/ls-as/ngram/tst.actions.subword.3gram.ppl\", \"lc-as_actions_3gram\", fold)\n",
    "\n",
    "    summarize(f\"../work/tree_per_line/**/{fold}/td/ngram/tst.actions.subword.4gram.ppl\", \"td_actions_4gram\", fold)\n",
    "    summarize(f\"../work/tree_per_line/**/{fold}/lc-as/ngram/tst.actions.subword.4gram.ppl\", \"lc-as_actions_4gram\", fold)\n",
    "\n",
    "    summarize(f\"../work/tree_per_line/**/{fold}/td/ngram/tst.actions.subword.5gram.ppl\", \"td_actions_5gram\", fold)\n",
    "    summarize(f\"../work/tree_per_line/**/{fold}/lc-as/ngram/tst.actions.subword.5gram.ppl\", \"lc-as_actions_5gram\", fold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural LMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Transformer\"\n",
    "folds = [\"0\", \"20000\", \"40000\", \"60000\", \"80000\"]\n",
    "for fold in folds:\n",
    "    files = glob.glob(f\"../work/results/**/{fold}/fairseq/trans/test.results\", recursive=True)\n",
    "    lang2ppl = {}\n",
    "    for file in files:\n",
    "        with open(file) as f:\n",
    "            lang = file.split(\"/\")[-5]\n",
    "            lines = f.readlines()\n",
    "            ppl_line = lines[-1].strip()\n",
    "            ppl = float(ppl_line.split(\"Perplexity:\")[-1].strip())\n",
    "            lang2ppl[lang] = ppl\n",
    "    lang2ppl = marginalize_complementizer(lang2ppl)\n",
    "    json.dump(lang2ppl, open(f\"../work/lang_ppl_distributions/{model_name}_fold{fold}.json\", \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"LSTM\"\n",
    "folds = [\"0\", \"20000\", \"40000\", \"60000\", \"80000\"]\n",
    "for fold in folds:\n",
    "    files = glob.glob(f\"../work/results/**/{fold}/fairseq/lstm/test.results\", recursive=True)\n",
    "\n",
    "    lang2ppl = {}\n",
    "    for file in files:\n",
    "        with open(file) as f:\n",
    "            lang = file.split(\"/\")[-5]\n",
    "            lines = f.readlines()\n",
    "            ppl_line = lines[-1].strip()\n",
    "            ppl = float(ppl_line.split(\"Perplexity:\")[-1].strip())\n",
    "            lang2ppl[lang] = ppl\n",
    "    lang2ppl = marginalize_complementizer(lang2ppl)\n",
    "    json.dump(lang2ppl, open(f\"../work/lang_ppl_distributions/{model_name}_fold{fold}.json\", \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"RNN\"\n",
    "folds = [\"0\", \"20000\", \"40000\", \"60000\", \"80000\"]\n",
    "for fold in folds:\n",
    "    files = glob.glob(f\"../work/results/**/{fold}/fairseq/rnn/test.results\", recursive=True)\n",
    "\n",
    "    lang2ppl = {}\n",
    "    for file in files:\n",
    "        with open(file) as f:\n",
    "            lang = file.split(\"/\")[-5]\n",
    "            lines = f.readlines()\n",
    "            ppl_line = lines[-1].strip()\n",
    "            ppl = float(ppl_line.split(\"Perplexity:\")[-1].strip())\n",
    "            lang2ppl[lang] = ppl\n",
    "\n",
    "    lang2ppl = marginalize_complementizer(lang2ppl)\n",
    "    json.dump(lang2ppl, open(f\"../work/lang_ppl_distributions/{model_name}_fold{fold}.json\", \"w\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural PLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Transformer-action_td\"\n",
    "folds = [\"0\", \"20000\", \"40000\", \"60000\", \"80000\"]\n",
    "for fold in folds:\n",
    "    files = glob.glob(f\"../work/results/**/{fold}/td/fairseq/trans/test.results\", recursive=True)\n",
    "    lang2ppl = {}\n",
    "    for file in files:\n",
    "        with open(file) as f:\n",
    "            lang = file.split(\"/\")[-5]\n",
    "            lines = f.readlines()\n",
    "            ppl_line = lines[-1].strip()\n",
    "            ppl = float(ppl_line.split(\"Perplexity:\")[-1].strip())\n",
    "            lang2ppl[lang] = ppl\n",
    "    lang2ppl = marginalize_complementizer(lang2ppl)\n",
    "    json.dump(lang2ppl, open(f\"../work/lang_ppl_distributions/{model_name}_fold{fold}.json\", \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Transformer-action_lc-as\"\n",
    "folds = [\"0\", \"20000\", \"40000\", \"60000\", \"80000\"]\n",
    "for fold in folds:\n",
    "    files = glob.glob(f\"../work/results/**/{fold}/lc-as/fairseq/trans/test.results\", recursive=True)\n",
    "    lang2ppl = {}\n",
    "    for file in files:\n",
    "        with open(file) as f:\n",
    "            lang = file.split(\"/\")[-5]\n",
    "            lines = f.readlines()\n",
    "            ppl_line = lines[-1].strip()\n",
    "            ppl = float(ppl_line.split(\"Perplexity:\")[-1].strip())\n",
    "            lang2ppl[lang] = ppl\n",
    "    lang2ppl = marginalize_complementizer(lang2ppl)\n",
    "    json.dump(lang2ppl, open(f\"../work/lang_ppl_distributions/{model_name}_fold{fold}.json\", \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"LSTM-action_td\"\n",
    "folds = [\"0\", \"20000\", \"40000\", \"60000\", \"80000\"]\n",
    "for fold in folds:\n",
    "    files = glob.glob(f\"../work/results/**/{fold}/td/fairseq/lstm/test.results\", recursive=True)\n",
    "    lang2ppl = {}\n",
    "    for file in files:\n",
    "        with open(file) as f:\n",
    "            lang = file.split(\"/\")[-5]\n",
    "            lines = f.readlines()\n",
    "            ppl_line = lines[-1].strip()\n",
    "            ppl = float(ppl_line.split(\"Perplexity:\")[-1].strip())\n",
    "            lang2ppl[lang] = ppl\n",
    "    lang2ppl = marginalize_complementizer(lang2ppl)\n",
    "    json.dump(lang2ppl, open(f\"../work/lang_ppl_distributions/{model_name}_fold{fold}.json\", \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"LSTM-action_lc-as\"\n",
    "folds = [\"0\", \"20000\", \"40000\", \"60000\", \"80000\"]\n",
    "for fold in folds:\n",
    "    files = glob.glob(f\"../work/results/**/{fold}/lc-as/fairseq/lstm/test.results\", recursive=True)\n",
    "    lang2ppl = {}\n",
    "    for file in files:\n",
    "        with open(file) as f:\n",
    "            lang = file.split(\"/\")[-5]\n",
    "            lines = f.readlines()\n",
    "            ppl_line = lines[-1].strip()\n",
    "            ppl = float(ppl_line.split(\"Perplexity:\")[-1].strip())\n",
    "            lang2ppl[lang] = ppl\n",
    "    lang2ppl = marginalize_complementizer(lang2ppl)\n",
    "    json.dump(lang2ppl, open(f\"../work/lang_ppl_distributions/{model_name}_fold{fold}.json\", \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"RNN-action_td\"\n",
    "folds = [\"0\", \"20000\", \"40000\", \"60000\", \"80000\"]\n",
    "for fold in folds:\n",
    "    files = glob.glob(f\"../work/results/**/{fold}/td/fairseq/rnn/test.results\", recursive=True)\n",
    "    lang2ppl = {}\n",
    "    for file in files:\n",
    "        with open(file) as f:\n",
    "            lang = file.split(\"/\")[-5]\n",
    "            lines = f.readlines()\n",
    "            ppl_line = lines[-1].strip()\n",
    "            ppl = float(ppl_line.split(\"Perplexity:\")[-1].strip())\n",
    "            lang2ppl[lang] = ppl\n",
    "    lang2ppl = marginalize_complementizer(lang2ppl)\n",
    "    json.dump(lang2ppl, open(f\"../work/lang_ppl_distributions/{model_name}_fold{fold}.json\", \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"RNN-action_lc-as\"\n",
    "folds = [\"0\", \"20000\", \"40000\", \"60000\", \"80000\"]\n",
    "for fold in folds:\n",
    "    files = glob.glob(f\"../work/results/**/{fold}/lc-as/fairseq/rnn/test.results\", recursive=True)\n",
    "    lang2ppl = {}\n",
    "    for file in files:\n",
    "        with open(file) as f:\n",
    "            lang = file.split(\"/\")[-5]\n",
    "            lines = f.readlines()\n",
    "            ppl_line = lines[-1].strip()\n",
    "            ppl = float(ppl_line.split(\"Perplexity:\")[-1].strip())\n",
    "            lang2ppl[lang] = ppl\n",
    "    lang2ppl = marginalize_complementizer(lang2ppl)\n",
    "    json.dump(lang2ppl, open(f\"../work/lang_ppl_distributions/{model_name}_fold{fold}.json\", \"w\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNNG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"RNNG_top_down\"\n",
    "folds = [\"0\", \"20000\", \"40000\", \"60000\", \"80000\"]\n",
    "for fold in folds:\n",
    "    lang2ppl = {}\n",
    "    if fold == \"0\":\n",
    "        df = pd.read_csv(\"../work/summary/RNNG.csv\", dtype={\"lang\": \"str\"})\n",
    "        df = df[(df[\"traversal\"]==\"top_down\") & (df[\"fold\"]==0)][[\"lang\", \"Test ppl\"]]\n",
    "        for row in df[[\"lang\", \"Test ppl\"]].iterrows():\n",
    "            lang = row[1][0]\n",
    "            if len(lang) == 7:\n",
    "                lang2ppl[lang] = row[1][1]\n",
    "    else:\n",
    "        files = glob.glob(f\"../work/results/**/{fold}/top_down/rnng/model.bin.log\", recursive=True)\n",
    "        for file in files:\n",
    "            lang = file.split(\"/\")[-5]\n",
    "            with open(file) as f:\n",
    "                result_line = [line for line in f if \"'Step': 11, 'Test ppl':\" in line]\n",
    "                if result_line:\n",
    "                    ppl = float(result_line[0].split(\"'Test ppl':\")[1].strip().split(\",\")[0])\n",
    "                    lang2ppl[lang] = ppl\n",
    "\n",
    "    lang2ppl = marginalize_complementizer(lang2ppl)\n",
    "    json.dump(lang2ppl, open(f\"../work/lang_ppl_distributions/{model_name}_fold{fold}.json\", \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"RNNG_in_order\"\n",
    "folds = [\"0\", \"20000\", \"40000\", \"60000\", \"80000\"]\n",
    "for fold in folds:\n",
    "    lang2ppl = {}\n",
    "    if fold == \"0\":\n",
    "        df = pd.read_csv(\"../work/pre-results/RNNG.csv\", dtype={\"lang\": \"str\"})\n",
    "        df = df[(df[\"traversal\"]==\"in_order\") & (df[\"fold\"]==0)][[\"lang\", \"Test ppl\"]]\n",
    "        for row in df[[\"lang\", \"Test ppl\"]].iterrows():\n",
    "            lang = row[1][0]\n",
    "            if len(lang) == 7:\n",
    "                lang2ppl[lang] = row[1][1]\n",
    "    else:\n",
    "        files = glob.glob(f\"../work/results/**/{fold}/in_order/rnng/model.bin.log\", recursive=True)\n",
    "        for file in files:\n",
    "            lang = file.split(\"/\")[-5]\n",
    "            with open(file) as f:\n",
    "                result_line = [line for line in f if \"'Step': 11, 'Test ppl':\" in line]\n",
    "                if result_line:\n",
    "                    ppl = float(result_line[0].split(\"'Test ppl':\")[1].strip().split(\",\")[0])\n",
    "                    lang2ppl[lang] = ppl\n",
    "\n",
    "    lang2ppl = marginalize_complementizer(lang2ppl)\n",
    "    json.dump(lang2ppl, open(f\"../work/lang_ppl_distributions/{model_name}_fold{fold}.json\", \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"RNNG_top_down_beam\"\n",
    "folds = [\"0\", \"20000\", \"40000\", \"60000\", \"80000\"]\n",
    "for fold in folds:\n",
    "    lang2ppl = defaultdict(list)\n",
    "    files = glob.glob(f\"../work/results/**/{fold}/top_down/rnng/model.bin.surprisals.fixed_beam.100_10_1\", recursive=True)\n",
    "    for file in files:\n",
    "        lang = file.split(\"/\")[-5]\n",
    "        with open(file) as f:\n",
    "            result_line = [line for line in f if 'perplexity' in line]\n",
    "            if result_line:\n",
    "                result = result_line[0]\n",
    "                ppl = float(result.split()[1])\n",
    "                lang2ppl[lang].append(ppl)\n",
    "    lang2ppl = {lang: mean(ppls) for lang, ppls in lang2ppl.items()}\n",
    "    lang2ppl = marginalize_complementizer(lang2ppl)\n",
    "    json.dump(lang2ppl, open(f\"../work/lang_ppl_distributions/{model_name}_fold{fold}.json\", \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"RNNG_in_order_beam\"\n",
    "folds = [\"0\", \"20000\", \"40000\", \"60000\", \"80000\"]\n",
    "for fold in folds:\n",
    "    lang2ppl = defaultdict(list)\n",
    "    files = glob.glob(f\"../work/results/**/{fold}/in_order/rnng/model.bin.surprisals.fixed_beam.100_10_1\", recursive=True)\n",
    "    for file in files:\n",
    "        lang = file.split(\"/\")[-5]\n",
    "        with open(file) as f:\n",
    "            result_line = [line for line in f if 'perplexity' in line]\n",
    "            if result_line:\n",
    "                result = result_line[0]\n",
    "                ppl = float(result.split()[1])\n",
    "                lang2ppl[lang].append(ppl)\n",
    "    lang2ppl = {lang: mean(ppls) for lang, ppls in lang2ppl.items()}\n",
    "    lang2ppl = marginalize_complementizer(lang2ppl)\n",
    "    json.dump(lang2ppl, open(f\"../work/lang_ppl_distributions/{model_name}_fold{fold}.json\", \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"SRNNG_top_down\"\n",
    "folds = [\"0\", \"20000\", \"40000\", \"60000\", \"80000\"]\n",
    "for fold in folds:\n",
    "    lang2ppl = {}\n",
    "    if fold == \"0\":\n",
    "        df = pd.read_csv(\"../work/pre-results/RNNG_weak_all.csv\", dtype={\"lang\": \"str\"})\n",
    "        df = df[(df[\"traversal\"]==\"top_down\")][[\"lang\", \"Test ppl\"]]\n",
    "        for row in df[[\"lang\", \"Test ppl\"]].iterrows():\n",
    "            lang = row[1][0]\n",
    "            if len(lang) == 7:\n",
    "                lang2ppl[lang] = row[1][1]\n",
    "    else:\n",
    "        files = glob.glob(f\"../work/results/basic/**/{fold}/top_down/srnng/model.bin.log\", recursive=True)\n",
    "        for file in files:\n",
    "            lang = file.split(\"/\")[-5]\n",
    "            with open(file) as f:\n",
    "                result_line = [line for line in f if \"'Step': 11, 'Test ppl':\" in line]\n",
    "                if result_line:\n",
    "                    ppl = float(result_line[0].split(\"'Test ppl':\")[1].strip().split(\",\")[0])\n",
    "                    lang2ppl[lang] = ppl\n",
    "\n",
    "    lang2ppl = marginalize_complementizer(lang2ppl)\n",
    "    json.dump(lang2ppl, open(f\"../work/lang_ppl_distributions/{model_name}_fold{fold}.json\", \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"SRNNG_in_order\"\n",
    "folds = [\"0\", \"20000\", \"40000\", \"60000\", \"80000\"]\n",
    "for fold in folds:\n",
    "    lang2ppl = {}\n",
    "    if fold == \"0\":\n",
    "        df = pd.read_csv(\"../work/pre-results/RNNG_weak_all.csv\", dtype={\"lang\": \"str\"})\n",
    "        df = df[(df[\"traversal\"]==\"in_order\")][[\"lang\", \"Test ppl\"]]\n",
    "        for row in df[[\"lang\", \"Test ppl\"]].iterrows():\n",
    "            lang = row[1][0]\n",
    "            if len(lang) == 7:\n",
    "                lang2ppl[lang] = row[1][1]\n",
    "    else:\n",
    "        files = glob.glob(f\"../work/results/**/{fold}/in_order/srnng/model.bin.log\", recursive=True)\n",
    "        for file in files:\n",
    "            lang = file.split(\"/\")[-5]\n",
    "            with open(file) as f:\n",
    "                result_line = [line for line in f if \"'Step': 11, 'Test ppl':\" in line]\n",
    "                if result_line:\n",
    "                    ppl = float(result_line[0].split(\"'Test ppl':\")[1].strip().split(\",\")[0])\n",
    "                    lang2ppl[lang] = ppl\n",
    " \n",
    "    lang2ppl = marginalize_complementizer(lang2ppl)\n",
    "    json.dump(lang2ppl, open(f\"../work/lang_ppl_distributions/{model_name}_fold{fold}.json\", \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"SRNNG_top_down_beam\"\n",
    "folds = [\"0\", \"20000\", \"40000\", \"60000\", \"80000\"]\n",
    "for fold in folds:\n",
    "    lang2ppl = defaultdict(list)\n",
    "    files = glob.glob(f\"../work/results/**/{fold}/top_down/srnng/model.bin.surprisals.fixed_beam.100_10_1\", recursive=True)\n",
    "    for file in files:\n",
    "        lang = file.split(\"/\")[-5]\n",
    "        with open(file) as f:\n",
    "            result_line = [line for line in f if 'perplexity' in line]\n",
    "            if result_line:\n",
    "                result = result_line[0]\n",
    "                ppl = float(result.split()[1])\n",
    "                lang2ppl[lang].append(ppl)\n",
    "\n",
    "    lang2ppl = {lang: mean(ppls) for lang, ppls in lang2ppl.items()}\n",
    "    lang2ppl = marginalize_complementizer(lang2ppl)\n",
    "    json.dump(lang2ppl, open(f\"../work/lang_ppl_distributions/{model_name}_fold{fold}.json\", \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"SRNNG_in_order_beam\"\n",
    "folds = [\"0\", \"20000\", \"40000\", \"60000\", \"80000\"]\n",
    "for fold in folds:\n",
    "    lang2ppl = defaultdict(list)\n",
    "    files = glob.glob(f\"../work/results/**/{fold}/in_order/srnng/model.bin.surprisals.fixed_beam.100_10_1\", recursive=True)\n",
    "    for file in files:\n",
    "        lang = file.split(\"/\")[-5]\n",
    "        with open(file) as f:\n",
    "            result_line = [line for line in f if 'perplexity' in line]\n",
    "            if result_line:\n",
    "                result = result_line[0]\n",
    "                ppl = float(result.split()[1])\n",
    "                lang2ppl[lang].append(ppl)\n",
    "    lang2ppl = {lang: mean(ppls) for lang, ppls in lang2ppl.items()}\n",
    "    lang2ppl = marginalize_complementizer(lang2ppl)\n",
    "    json.dump(lang2ppl, open(f\"../work/lang_ppl_distributions/{model_name}_fold{fold}.json\", \"w\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLama2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"llama2-7b\"\n",
    "folds = [\"0\", \"20000\", \"40000\", \"60000\", \"80000\"]\n",
    "for fold in folds:\n",
    "    lang2ppl = defaultdict(list)\n",
    "    files = glob.glob(f\"../work/results/**/{fold}/Llama-2-7b-hf/ppl.txt\", recursive=True)\n",
    "    for file in files:\n",
    "        lang = file.split(\"/\")[-4]\n",
    "        with open(file) as f:\n",
    "            result_line = f.readlines()\n",
    "            if result_line:\n",
    "                result = result_line[0]\n",
    "                ppl = float(result.strip())\n",
    "                lang2ppl[lang].append(ppl)\n",
    "    lang2ppl = {lang: mean(ppls) for lang, ppls in lang2ppl.items()}\n",
    "    lang2ppl = marginalize_complementizer(lang2ppl)\n",
    "    json.dump(lang2ppl, open(f\"../work/lang_ppl_distributions/{model_name}_fold{fold}.json\", \"w\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
